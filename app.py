import streamlit as st
import sys
import time
import Speech_to_Text
import Agent
import RAG
from Text_to_Speech import speak_text_from_file
import streamlit_mic_recorder as mic_recorder
# Ù…Ø§ Ø¯ÛŒÚ¯Ø± Ø¨Ù‡ ØªØ§Ø¨Ø¹ speak_text_from_file Ù†ÛŒØ§Ø²ÛŒ Ù†Ø¯Ø§Ø±ÛŒÙ…

def write_to_say(context):
    """Ù…ØªÙ† Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ to_say.txt Ù…ÛŒâ€ŒÙ†ÙˆÛŒØ³Ø¯."""
    try:
        with open("to_say.txt", "w", encoding="utf-8") as f:
            f.write(context)
    except Exception as e:
        print(f"Error writing to 'to_say.txt': {e}")
        st.error(f"Error writing file: {e}")

@st.cache_resource
def initial_setup():
    """RAG Ø±Ø§ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ù…Ø¯Ù„ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    print("--- ONE-TIME SETUP ---")
    print("Running RAG ingestion...")
    RAG.run_ingestion()
    print("Loading embedding model...")
    embeddings = RAG.get_embedding_model()
    print("--- Setup Complete ---")
    return embeddings

# --- Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ ---
st.set_page_config(page_title="Ø¯Ø³ØªÛŒØ§Ø± Ø±Ø¨Ø§ØªÛŒÚ© IUT", layout="centered")
st.title("ğŸ¤– Ø¯Ø³ØªÛŒØ§Ø± Ù…Ø³Ø§Ø¨Ù‚Ø§Øª Ø±Ø¨Ø§ØªÛŒÚ© IUT")

# Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ (Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ...)
embedding_model = initial_setup()

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        if message["role"] == "assistant" and "video" in message:
            st.video(message["video"], loop=True, autoplay=True, muted=True)
            st.audio(message["audio"], autoplay=True)

st.write("---")
if st.button("ğŸ™ï¸ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø³ÛŒØ¯Ù† Ø³ÙˆØ§Ù„ Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯ (ÛŒØ§ Ù†Ú¯Ù‡ Ø¯Ø§Ø±ÛŒØ¯)"):
    
    final_answer = ""
    user_question = ""
    
    with st.spinner("ğŸ§ Ø¯Ø± Ø­Ø§Ù„ Ø´Ù†ÛŒØ¯Ù†..."):
        user_question = Speech_to_Text.speech_to_text()

    if user_question:
        st.chat_message("user").markdown(user_question)
        st.session_state.messages.append({"role": "user", "content": user_question})

        with st.spinner("ğŸ§  Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´..."):
            route = Agent.route(user_question)
            
            if route == "DOCUMENT":
                context = RAG.query_vector_store(user_question, embedding_model)
                if context is None:
                    final_answer = Agent.generate_general_answer(user_question)
                else:
                    final_answer = Agent.generate_rag_answer(user_question, context)
            
            elif route == "GENERAL":
                final_answer = Agent.generate_general_answer(user_question)

        # 3. ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
        with st.spinner("ğŸ’¬ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØµØ¯Ø§..."):
            write_to_say(final_answer)
            # Ø§Ø² ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ÛŒ Ú©Ù‡ Ø³Ø§Ø®ØªÛŒÙ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            generation_success = speak_text_from_file() 
        
        # 4. Ù†Ù…Ø§ÛŒØ´ Ù¾Ø§Ø³Ø® Ù†Ù‡Ø§ÛŒÛŒ (ÙˆÛŒØ¯ÛŒÙˆ Ùˆ ØµØ¯Ø§)
        if generation_success:
            video_file = "Cute_Robot.mp4"
            audio_file = "Say.mp3"

            with st.chat_message("assistant"):
                st.markdown(final_answer)
                st.video(video_file, loop=True, autoplay=True, muted=True) # ÙˆÛŒØ¯ÛŒÙˆ (Ø¨ÛŒâ€ŒØµØ¯Ø§)
                st.audio(audio_file, autoplay=True) # ØµØ¯Ø§
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ (Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ ÙˆÛŒØ¯ÛŒÙˆ Ùˆ ØµØ¯Ø§)
            st.session_state.messages.append({
                "role": "assistant", 
                "content": final_answer,
                "video": video_file,
                "audio": audio_file
            })
        else:
            st.error("Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ.")

    else:
        st.warning("ØµØ¯Ø§ÛŒÛŒ Ø´Ù†ÛŒØ¯Ù‡ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")